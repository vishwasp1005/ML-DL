ğŸš€ Day 2 Completed: Data Encoding, Missing Value Strategy, Model Evaluation Metrics, Regression Techniques, and Feature Scaling Implementation Notes.


ğŸ”¥ 1. Encoding Techniques
<details> <summary><strong>ğŸ”¹ Why Encoding? (Click to expand)</strong></summary>

Machine Learning models understand numbers only â€” not text.
So categorical features must be converted to numerical form.

</details>
â­ â‘  Label Encoding (Ordered Categories)

ğŸ“Œ Use when categories have rank/order
(e.g., Low < Medium < High)

â­ â‘¡ One Hot Encoding (Non-Ordered Categories)

ğŸ“Œ Use when categories have no order

df = pd.get_dummies(df, columns=['Color'], drop_first=True)


ğŸ“ drop_first=True â†’ prevents dummy variable trap


## ğŸ”§ 2. Handling Missing Values

| Technique | Best For                     | Code Example                                                     |
|-----------|-------------------------------|------------------------------------------------------------------|
| Mean      | Normal numeric                | `df['Age'].fillna(df['Age'].mean(), inplace=True)`              |
| Median    | Skewed numeric / Outliers     | `df['Income'].fillna(df['Income'].median(), inplace=True)`      |
| Mode      | Categorical                   | `df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)`     |



âœ‚ï¸ 3. Trainâ€“Test Split


from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)


ğŸ¯ Used to evaluate model performance on unseen data


ğŸ“Š 4. Evaluation Metrics
<details> <summary><strong>ğŸ“‰ Regression Metrics (Click to expand)</strong></summary>
MSE â€“ Mean Squared Error
RMSE â€“ Root MSE
rmse = mse ** 0.5
MAE â€“ Mean Absolute Error
RÂ² Score
    
ğŸ’¡ Higher RÂ² = Better model

</details>
ğŸ§® 5. Multiple Linear Regression


ğŸ“˜ Formula  y=b0â€‹+b1â€‹x1â€‹+b2â€‹x2â€‹+...+bnâ€‹xnâ€‹

ğŸŒ€ 6. Polynomial Regression

ğŸ“Œ Used for non-linear relationships.

âš™ï¸ Formula  y=b0â€‹+b1â€‹x+b2â€‹x2+b3â€‹x3+...

âš¡ 7. Feature Scaling
â­ Standardization (Z-Score)

Used in: SVM, Logistic Regression, KNN, Neural Networks

â­ Normalization (Min-Max)

Scales between 0 and 1

## ğŸ DAY 2 â€” Summary Table

| Topic                   | Why Use                 | Notes                          |
|------------------------|--------------------------|--------------------------------|
| Label Encoding         | Ordered labels           | Converts text â†’ numbers        |
| One Hot Encoding       | Non-ordered labels       | Avoid dummy trap               |
| Missing Values         | Clean dataset            | Mean / Median / Mode           |
| Trainâ€“Test Split       | Unseen evaluation        | test_size = 0.2                |
| MSE / RMSE             | Error measurement        | RMSE easiest                   |
| MAE                    | Outlier safe             | Absolute difference            |
| RÂ² Score               | Goodness of fit          | Closer to 1 = good             |
| Multiple Linear Reg.   | Multiple inputs          | Linear relationship            |
| Polynomial Regression  | Non-linear curve         | degree = 2/3                   |
| Standardization        | Gradient models          | mean = 0                       |
| Normalization          | NN & bounded models      | Scales 0â€“1                     |
